{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # Стандартизируем все новые добавленные колонки\\nfor feature in numeric_features:\\n    X[f\"{feature}_log\"] = scaler.fit_transform(X[[f\"{feature}_log\"]])\\n    X[f\"{feature}_squared\"] = scaler.fit_transform(X[[f\"{feature}_squared\"]])\\n    X[f\"{feature}_cubed\"] = scaler.fit_transform(X[[f\"{feature}_cubed\"]]) '"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv(\"Zadanie_1.csv\")\n",
    "\n",
    "# Выбираем факторные признаки (числовые признаки)\n",
    "numeric_features = [\n",
    "    \"na_sales\",\n",
    "    \"eu_sales\",\n",
    "    \"other_sales\",\n",
    "\n",
    "]\n",
    "\n",
    "# Выбираем категориальные признаки для кодирования\n",
    "categorical_features = [\n",
    "    \"year\",\n",
    "    \"platform\",\n",
    "    \"genre\",\n",
    "\t\"publisher\",\n",
    "]\n",
    "\n",
    "\n",
    "# Применяем One-Hot Encoding к категориальным признакам\n",
    "encoder = OneHotEncoder()\n",
    "encoded_features = encoder.fit_transform(data[categorical_features])\n",
    "\n",
    "# Соединяем числовые и закодированные категориальные признаки\n",
    "X = pd.concat([data[numeric_features], pd.DataFrame(encoded_features.toarray())], axis=1)\n",
    "\n",
    "# Добавим константный признак для обучения свободного члена модели\n",
    "X['const'] = 1\n",
    "\n",
    "# Отдельно выбираем результативный признак (jp_sales)\n",
    "y = data[\"jp_sales\"]\n",
    "\n",
    "\"\"\" # Добавление логарифмов, квадратов и кубов числовых признаков\n",
    "for feature in numeric_features:\n",
    "    # Проверка на нулевые значения перед вычислением логарифмов\n",
    "    if (X[feature] != 0).any():\n",
    "        X[f\"{feature}_log\"] = 0  # Заменяем нули на ноль в логарифмах\n",
    "    else:\n",
    "        X[f\"{feature}_log\"] = np.log(X[feature])\n",
    "    X[f\"{feature}_squared\"] = X[feature] ** 2\n",
    "    X[f\"{feature}_cubed\"] = X[feature] ** 3 \"\"\"\n",
    "\n",
    "\n",
    "# Создаем объект StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Стандартизируем числовые признаки\n",
    "X[numeric_features] = scaler.fit_transform(X[numeric_features])\n",
    "\n",
    "\"\"\" # Стандартизируем все новые добавленные колонки\n",
    "for feature in numeric_features:\n",
    "    X[f\"{feature}_log\"] = scaler.fit_transform(X[[f\"{feature}_log\"]])\n",
    "    X[f\"{feature}_squared\"] = scaler.fit_transform(X[[f\"{feature}_squared\"]])\n",
    "    X[f\"{feature}_cubed\"] = scaler.fit_transform(X[[f\"{feature}_cubed\"]]) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.17797222675231344\n",
      "Mean Absolute Percentage Error (MAPE): 12.317267874951058\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MultipleRegression:\n",
    "\n",
    "    def __init__(self, learning_rate=0.1, n_iterations=100):\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.weights = np.zeros(X.shape[1])\n",
    "\n",
    "    def calculate_gradient(self, X, y):\n",
    "\n",
    "        n_samples = X.shape[0]\n",
    "        y_pred = X.dot(self.weights)\n",
    "        error = y_pred - y\n",
    "        gradient = X.T.dot(error) / n_samples\n",
    "        return gradient\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "\n",
    "        for _ in range(self.n_iterations):\n",
    "            gradient = self.calculate_gradient(X, y)\n",
    "            self.weights -= self.learning_rate * gradient\n",
    "\n",
    "        \n",
    "    def predict(self, X):\n",
    "\n",
    "        return X.dot(self.weights)\n",
    "\n",
    "# Создаем и обучаем модель\n",
    "model = MultipleRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Делаем окончательные прогнозы для jp_sales\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Вычисляем MAE и MAPE \n",
    "mae = np.mean(np.abs(y - y_pred))\n",
    "mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
    "\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", mape)\n",
    "#print(model.weights)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
